{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multiple Matrix Multiplication Tutorial\n",
                "\n",
                "In this example, we'll build on the Matmul Tutorial and include a second matrix multiplication. The end result being y = x^3 where x is the input matrix. We'll also include some of the concepts from the previous tutorials. \n",
                "\n",
                "By the end of this tutorial, you should feel comfortable with the following concepts:\n",
                "* Matrix Multiplication on Groq hardware\n",
                "* Memory Layouts for Tensors\n",
                "* Buffered Resource Scopes\n",
                "* Memory Copy\n",
                "\n",
                "It is expected that you have finished reading the Multiple Matrix Multiplications section of the Groq API Tutorial Guide prior to going through this tutorial. \n",
                "\n",
                "## Build a program and Compile with Groq API\n",
                "\n",
                "Begin by importing the following packages. Note that for this example, in addition to the Groq API, we're also importing the Neural Net library from the Groq API as 'nn'. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import groq.api as g\n",
                "from groq.runner import tsp\n",
                "import groq.api.nn as nn\n",
                "import numpy as np\n",
                "print(\"Python packages imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create your input matrix, set the size and datatype. Remember to name it for easier debug and provide the recommended memory layout for the first matrix."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matrix = g.input_tensor(shape=(120, 120), dtype=g.float16, name=\"matrix\", layout=\"H1(W), -1, S2\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Before looking at the code, let's discuss what this program will do:\n",
                "\n",
                "<b> STEPS: <b>\n",
                "\n",
                "1. First, we need to make a copy of our input matrix in order to do X*X. We'll use our learnings from the Memory Copy Tutorial to do this, however we'll include it inside a buffered resource scope. Doing a memory copy from within the GroqChip reduces the data being sent via the PCIe bus thereby reducing bloat on the bus.\n",
                "\n",
                "2. Now that we have two sets of 'x', we can multiply them together.\n",
                "\n",
                "3. Since the result of the matrix multiply is float32, we need to cast it to float16 before the second matrix multiply.\n",
                "\n",
                "4. Multiply the result after the cast with the copy of 'x' (this is because it's in the correct memory layout as the second matrix)\n",
                "\n",
                "5. Return the result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TopLevel(g.Component):  # Create our top level component\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.mm = nn.MatMul(name=\"MyMatMul\", arith_mode_warmup=True)     #Matmul 1: using the nn.MatMul() component.\n",
                "        self.mm2 = nn.MatMul(name=\"MyMatMul2\", arith_mode_warmup=True)   #Matmul 2: using the nn.MatMul() component.\n",
                "\n",
                "    def build(self, in1_mt, time=0):             #Provide the value of 'x' and a default time of 0\n",
                "        with g.ResourceScope(name=\"MemCopy\", is_buffered=True, time=0) as memcopy:   #STEP 1: COPY INPUT\n",
                "            in1_st = in1_mt.read(streams=g.SG2, time=0)\n",
                "            in1_copy_mt = in1_st.write(name=\"write_copy\", layout=\"H1(W), -1, S16(4-38)\")    #Assign a layout preferable to the MXM for the second matrix\n",
                "\n",
                "        with g.ResourceScope(name=\"mmscope\", is_buffered=True, predecessors=[memcopy], time=None) as mmscope :   #STEP2: MATMUL\n",
                "            result = self.mm(in1_mt, in1_copy_mt, time=0).write(name=\"mm_result\", layout=\"H1(W), -1, S4\")\n",
                "\n",
                "        with g.ResourceScope(name=\"cast\", is_buffered=True, time=None, predecessors=[mmscope]) as castscope:     #STEP3: CAST FP32 -> FP16\n",
                "            result_fp16_st = g.cast(result, dtype=g.float16, fp16_inf=False, time=0)    #fp16_inf = false is a non-saturating conversion\n",
                "            result_fp16_mt = result_fp16_st.write(name=\"write_cast\")\n",
                "        \n",
                "        with g.ResourceScope(name=\"mmscope2\", is_buffered=True, predecessors=[castscope], time=None) as mmscope2 :  #STEP4: MATMUL2\n",
                "            result_final = self.mm2(result_fp16_mt, in1_copy_mt, time=0).write(name=\"mm_result2\", layout=\"H1(W), -1, S4\")\n",
                "            g.add_mem_constraints([result_final], [result_fp16_mt, in1_copy_mt], g.MemConstraintType.BANK_EXCLUSIVE)\n",
                "        return result_final    #STEP5: FINAL ANSWER!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A couple points to remember about the API's Matrix Multiplication:\n",
                "* The Matrix Multiply in the Neural Net library expects two Rank-2 tensors and supports the following data types: \n",
                "  * int8 \n",
                "  * float16 \n",
                "  * Mixed float16/float32 (See API Reference Guide)\n",
                "* The API implicitly transposes the 2nd tensor before performing the matmul operation. \n",
                "* The inner dimension of both memory tensors must be the same.\n",
                "* For a float16 matmul, the recommended memory layout for the first matrix is `layout=\"H1(W), -1, S2\"` and the layout for the second matrix is `layout=\"H1(W), -1, S16(4-38)\"`, noting that the output is float32.\n",
                "* As always, name your tensors for easier debug"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "top = TopLevel()\n",
                "total_result = top(matrix, time=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compile the program:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iop_file = g.compile(base_name=\"multi_matmul\", result_tensor=total_result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GroqView\n",
                "GroqView can be used to view the instructions of your program in the GroqChip. Note: it is expected that you are familiar with the GroqView tool (See \"GroqView User Guide\") for this section of this tutorial. You may skip viewing the program in GroqView and move to the \"Prepare Data for Program\" section.\n",
                "\n",
                "Using the following command, we can create a .json file that can be used to view the program in hardware. This will show:\n",
                "* what instructions occur\n",
                "* where on the chip they take place, as well as \n",
                "* when in time (cycles) each instruction occurs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "g.write_visualizer_data(\"multi_matmul\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To launch GroqView, uncomment and run the following command. Remember, you still need to create a tunnel to the server running the GroqView tool to load in another window. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#!groqview multi_matmul/visdata.json"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<b>Note:</b> before proceeding to the next section, you'll want to stop the above cell. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run on Hardware\n",
                "Program the Groq Chip with the binary file of the Matrix Multiply program "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "program = tsp.create_tsp_runner(iop_file)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Provide the input data to the Groq Chip which will return the results of the matrix multiplication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Call the program and provide an input matrix\n",
                "t1_data = np.random.rand(120, 120).astype(np.float16)\n",
                "result = program(matrix=t1_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check Results\n",
                "Note that the oracle value is FLOAT32 because the output of the MXM matrix multiply is float32 for two Float16 inputs. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute the oracle value for comparison\n",
                "oracle = np.matmul(t1_data, t1_data.transpose(), dtype=np.float32)\n",
                "oracle = np.matmul(oracle, t1_data.transpose(), dtype=np.float32)\n",
                "\n",
                "# Ensure it matches the Groq Chip\n",
                "print(np.allclose(oracle, result['mm_result2'], rtol=1e-1, atol=1e-1, equal_nan=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Back to Back Computations\n",
                "The Groq Chip is still programmed with the matmul program so we can continue to provide input data and it will return the results of the matrix multiplied by itself twice. Now let's look at how we can perform calls to the same program repeatedly with different input tensors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for i in range(3):\n",
                "    print(f\"Matrix {i}\")\n",
                "    t1_data = np.random.rand(120, 120).astype(np.float16)\n",
                "    t2_data = np.random.rand(120, 120).astype(np.float16)\n",
                "    result = program(matrix=t1_data)\n",
                "    oracle = np.matmul(t1_data, t1_data.transpose(), dtype=np.float32)\n",
                "    oracle = np.matmul(oracle, t1_data.transpose(), dtype=np.float32)\n",
                "    print(\"For input tensor of size {}. Results are: \".format(t1_data.shape))\n",
                "    print(np.allclose(oracle, result['mm_result2'], rtol=1e-1, atol=1e-1, equal_nan=True))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}